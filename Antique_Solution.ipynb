{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c130e37-a029-4011-b741-14adb0bc15bb",
   "metadata": {},
   "source": [
    "<img src=\"./figs/IOAI-Logo.png\" alt=\"IOAI Logo\" width=\"200\" height=\"auto\">\n",
    "\n",
    "[IOAI 2025 (Beijing, China), Individual Contest](https://ioai-official.org/china-2025)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/IOAI-official/IOAI-2025/blob/main/Individual-Contest/Antique/Solution/Antique_Solution.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae71b15-8e97-4896-90a2-000c9cd6e683",
   "metadata": {},
   "source": [
    "# Antique Painting Authentication: Reference Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bf0dce",
   "metadata": {},
   "source": [
    "## Step 1: Train Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# 1. Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# 2. Check if the path contains \"Individual-Contest/Antique\" and trim it to that point\n",
    "if \"Individual-Contest/Antique\" in current_dir:\n",
    "    root_index = current_dir.index(\"Individual-Contest/Antique\") + len(\"Individual-Contest/Antique\")\n",
    "    project_root = current_dir[:root_index]\n",
    "else:\n",
    "    raise Exception(\"Project root directory not found. Please check the folder structure.\")\n",
    "\n",
    "# 3. Change working directory to the project root\n",
    "os.chdir(project_root)\n",
    "print(\"Working directory set to:\", os.getcwd())\n",
    "\n",
    "# 4. Add module search path (e.g., where metrics.py is located)\n",
    "sys.path.append(os.path.join(project_root, \"Scoring\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dae883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "\n",
    "TRAIN_PATH = \"./training_set/\" # The address of trainig set\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH + \"training_set.csv\")\n",
    "\n",
    "X = np.array(train.iloc[:,:5])\n",
    "y = np.array(train.iloc[:,5])\n",
    "\n",
    "labeled_mask = y != 0\n",
    "unlabeled_mask = y == 0\n",
    "X_labeled = X[labeled_mask]\n",
    "y_labeled = y[labeled_mask]\n",
    "X_unlabeled = X[unlabeled_mask]\n",
    "\n",
    "n_clusters = 2\n",
    "spectral = SpectralClustering(n_clusters=n_clusters, affinity='rbf', gamma=10, random_state=42)\n",
    "cluster_labels = spectral.fit_predict(X) \n",
    "\n",
    "cluster_to_label = {}\n",
    "for cluster in range(n_clusters):\n",
    "\n",
    "    labeled_in_cluster = y_labeled[cluster_labels[labeled_mask] == cluster]\n",
    "\n",
    "    if len(labeled_in_cluster) > 0:\n",
    "        most_common_label = Counter(labeled_in_cluster).most_common(1)[0][0]\n",
    "        cluster_to_label[cluster] = most_common_label\n",
    "\n",
    "pseudo_labels = np.array([cluster_to_label[cluster] for cluster in cluster_labels])\n",
    "\n",
    "svm = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "svm.fit(X, pseudo_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2049ba4",
   "metadata": {},
   "source": [
    "## Step 2: Make Predictions on the Validation and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_DATA_PATH = \"./Solution/validation_set/\"\n",
    "TEST_DATA_PATH = \"./Solution/test_set/\"\n",
    "\n",
    "testA = np.array(pd.read_csv(VAL_DATA_PATH + \"validation_set.csv\"))\n",
    "testB = np.array(pd.read_csv(TEST_DATA_PATH + \"test_set.csv\"))\n",
    "\n",
    "predA = svm.predict(testA)\n",
    "predB = svm.predict(testB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2141d8",
   "metadata": {},
   "source": [
    "## Step 3: Generate `submission.zip` for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e6ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "submissionA = pd.DataFrame(predA)\n",
    "submissionA.to_csv(\"./Scoring/submissionA.csv\", index=False, header=False)\n",
    "\n",
    "submissionB = pd.DataFrame(predB)\n",
    "submissionB.to_csv(\"./Scoring/submissionB.csv\", index=False, header=False)\n",
    "\n",
    "files_to_zip = ['./Scoring/submissionA.csv', './Scoring/submissionB.csv']\n",
    "zip_filename = './Scoring/submission.zip'\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "    for file in files_to_zip:\n",
    "        zipf.write(file, os.path.basename(file))\n",
    "\n",
    "print(f'{zip_filename} is created succefully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65766d9",
   "metadata": {},
   "source": [
    "### Evaluate the Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9f1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Scoring/metrics.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
